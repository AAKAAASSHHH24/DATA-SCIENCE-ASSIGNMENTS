{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is prior probability? Give an example.**\n"
      ],
      "metadata": {
        "id": "TU36puQwrRyn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prior probability is the probability of an event occurring before any new data or evidence is taken into account. An example of prior probability would be the probability of rolling a 6 on a fair die, which is 1/6."
      ],
      "metadata": {
        "id": "sB_F91LErlCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. What is posterior probability? Give an example.**\n"
      ],
      "metadata": {
        "id": "2RbQdpVlrV2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Posterior probability is the probability of an event occurring after new data or evidence is taken into account. An example of posterior probability would be the probability of a person having a certain disease, given a positive test result."
      ],
      "metadata": {
        "id": "Lb6hGK1ErqPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. What is likelihood probability? Give an example.**"
      ],
      "metadata": {
        "id": "KwCaDabNrbdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Likelihood probability is the probability of obtaining a certain set of data or evidence, given that a particular event has occurred. An example of likelihood probability would be the probability of getting a positive test result, given that a person has a certain disease."
      ],
      "metadata": {
        "id": "MG_3S-i6rt_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. What is Naïve Bayes classifier? Why is it named so?**"
      ],
      "metadata": {
        "id": "iTRWH9vgsfjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes classifier is a probabilistic machine learning algorithm that is based on the Bayes' theorem, which **describes the probability of an event occurring based on prior knowledge of conditions that might be related to the event.** \n",
        "\n",
        "The algorithm is called \"naive\" because it makes the **assumption that all the features in the data are independent of each other,** which is often not the case in real-world data. Despite this assumption, Naive Bayes classifiers often perform surprisingly well in practice.\n",
        "\n",
        "Naive Bayes classifiers are used for a variety of tasks, such as text classification, spam filtering, and sentiment analysis. They are particularly useful when the data is limited and the number of features is large. They are simple, easy to implement and computationally efficient which makes them a popular choice for many applications."
      ],
      "metadata": {
        "id": "HjEw7Y6gsbnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What is optimal Bayes classifier?**"
      ],
      "metadata": {
        "id": "_cccP4l9smzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An optimal Bayes classifier is a Bayesian classifier that makes the \"correct\" or \"optimal\" classification decision, **based on the underlying probability distribution of the data.**\n",
        "\n",
        "It is also known as the Bayes' optimal classifier, Bayes' risk classifier, or the Bayes' decision rule.\n",
        "\n",
        "The optimal Bayes classifier is the classifier that minimizes the probability of misclassification, given the prior probabilities of the classes and the likelihood of the features given the classes. In other words, it maximizes the probability of correct classification.\n",
        "\n",
        "**The optimal Bayes classifier is a theoretical concept, as it requires knowledge of the true underlying probability distributions of the data. In practice, we do not have access to this information and must approximate the classifier using a sample of the data.** The Naive Bayes Classifier is an example of an approximate Bayes classifier, that assume the independence of features, which is often not the case in real-world data."
      ],
      "metadata": {
        "id": "UtnKhcVgswl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Write any two features of Bayesian learning methods.**"
      ],
      "metadata": {
        "id": "q9QQ3UmlzSdo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two features of Bayesian learning methods are:\n",
        "They are based on the Bayes' theorem, which describes the probability of an event occurring based on prior knowledge of conditions that might be related to the event.\n",
        "They incorporate prior knowledge or information in the form of prior probabilities, which can be updated as new data is obtained."
      ],
      "metadata": {
        "id": "EgkqKR5fznzh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Define the concept of consistent learners.**"
      ],
      "metadata": {
        "id": "5gjDfpFSzWhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A consistent learner is a machine learning algorithm that asymptotically makes the correct classification decision as the amount of data increases. In other words, as the sample size increases, the error rate of the classifier will decrease towards zero."
      ],
      "metadata": {
        "id": "tzKjgoAnzr-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Write any two strengths of Bayes classifier.**"
      ],
      "metadata": {
        "id": "h5uyNQh0zeN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two strengths of Bayes classifiers are:\n",
        "\n",
        "They are computationally efficient, making them a good choice for applications with large amounts of data or many features.\n",
        "\n",
        "They can incorporate prior knowledge or information in the form of prior probabilities, which can be useful when data is limited."
      ],
      "metadata": {
        "id": "P7qefVEuzvyM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Write any two weaknesses of Bayes classifier.**"
      ],
      "metadata": {
        "id": "QIbciZVj1OTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two weaknesses of Bayes classifiers are:\n",
        "\n",
        "They assume independence between features, which is often not the case in real-world data. This assumption is called \"naive\" assumption, that's why it's called Naive Bayes classifier.\n",
        "\n",
        "They are sensitive to irrelevant features and the presence of irrelevant features can decrease the accuracy of the classifier.\n",
        "\n",
        "They also perform poorly if the number of data points is small. Since Bayesian methods are based on probability estimates, they require a significant amount of data to make accurate predictions."
      ],
      "metadata": {
        "id": "gjQFkkFZ1TIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. Explain how Naïve Bayes classifier is used for**\n",
        "\n",
        "**1. Text classification**\n",
        "\n",
        "**2. Spam filtering**\n",
        "\n",
        "**3. Market sentiment analysis**"
      ],
      "metadata": {
        "id": "XAnAA2Ea4DEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text classification:** \n",
        "\n",
        "In text classification, a Naive Bayes classifier is used to classify text into predefined categories such as spam or not spam, positive or negative sentiment, etc. The algorithm works by first converting the text into a set of features, such as the presence or absence of certain words or phrases. The classifier then uses these features, along with prior probabilities for each class, to calculate the posterior probability of each class for a given piece of text. The class with the highest probability is then chosen as the classification."
      ],
      "metadata": {
        "id": "8nQapsmn4RHY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spam filtering:** \n",
        "\n",
        "In spam filtering, a Naive Bayes classifier is used to classify email messages as spam or not spam. The algorithm works by first converting the email message into a set of features, such as the presence or absence of certain words or phrases. The classifier then uses these features, along with prior probabilities for each class, to calculate the posterior probability of each class for a given email message. The class with the highest probability is then chosen as the classification."
      ],
      "metadata": {
        "id": "fJkWnbgU4apw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Market sentiment analysis:** \n",
        "\n",
        "In market sentiment analysis, a Naive Bayes classifier is used to classify news articles, social media posts, or other forms of text as positive, negative or neutral sentiment. The algorithm works by first converting the text into a set of features, such as the presence or absence of certain words or phrases. The classifier then uses these features, along with prior probabilities for each class, to calculate the posterior probability of each class for a given piece of text. The class with the highest probability is then chosen as the classification.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YGAfJVJX5Ed1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwmQYLK_rJR5"
      },
      "outputs": [],
      "source": []
    }
  ]
}