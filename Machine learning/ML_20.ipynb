{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is the underlying concept of Support Vector Machines?**"
      ],
      "metadata": {
        "id": "hJFY2wMkt4SI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The underlying concept of Support Vector Machines (SVMs) is to find a decision boundary that maximally separates different classes in the dataset. This decision boundary is called a hyperplane, which is a subspace of one dimension less than the input space. SVMs try to find the hyperplane that has the largest margin, which is defined as the distance between the hyperplane and the closest data points from each class, called support vectors. The idea is that, by maximizing the margin, the model will be more robust to noise and less sensitive to outliers. Once the decision boundary is found, new data points can be classified by determining on which side of the hyperplane they fall."
      ],
      "metadata": {
        "id": "fw68qxjat9sX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. When using SVMs, why is it necessary to scale the inputs?**"
      ],
      "metadata": {
        "id": "wHuy4axKunUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When using SVMs, it is necessary to scale the inputs because the SVM optimization algorithm attempts to find the maximum margin between the classes, which is defined by the distance between the closest points from each class. If the input features are not scaled, some features may have a much larger scale than others, which would give them more weight in the optimization process and potentially lead to suboptimal solutions."
      ],
      "metadata": {
        "id": "MJB6zrtOujTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. When an SVM classifier classifies a case, can it output a confidence score? What about a\n",
        "percentage chance?**"
      ],
      "metadata": {
        "id": "G8CuQn-cuwio"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An SVM classifier can output a confidence score, but it is not as straightforward as some other classification methods. This is because SVMs are based on a margin-based approach, which does not directly provide a probability estimate. However, it is possible to use techniques such as Platt Scaling to estimate the probability of a case belonging to a certain class. It is also possible to output a percentage chance, but this would require additional steps such as the above mentioned Platt Scaling or using techniques such as cross-validation to estimate the confidence."
      ],
      "metadata": {
        "id": "EvFLFTQwutjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Should you train a model on a training set with millions of instances and hundreds of features\n",
        "using the primal or dual form of the SVM problem?**"
      ],
      "metadata": {
        "id": "OlQJcI-SvtQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of whether to train an SVM model on a training set with millions of instances and hundreds of features using the primal or dual form of the problem depends on the size of the dataset.\n",
        "\n",
        "If the number of instances is larger than the number of features, the primal form of the SVM problem is more appropriate, as it scales better with the number of instances. However, if the number of features is larger than the number of instances, the dual form of the SVM problem is more appropriate, as it scales better with the number of features.\n",
        "\n",
        "It is worth noting that the primal form of the SVM problem can be memory-intensive and computationally expensive for large datasets, as it requires the storage and inversion of a matrix whose size is proportional to the number of instances. On the other hand, the dual form of the SVM problem is more computationally efficient, but it requires the storage of all pairwise products between the instances, which can also be memory-intensive for large datasets.\n",
        "\n",
        "So, if you have a large number of instances and only a moderate number of features, the primal form is preferred.\n",
        "If the number of features is larger than the number of instances, the dual form is a better choice.\n",
        "\n",
        "It is also important to note that the use of kernel functions can help in high dimensional cases and help to use the dual form even when the number of instances is larger than the number of features."
      ],
      "metadata": {
        "id": "DCW7ZXeovzp_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Let&#39;s say you&#39;ve used an RBF kernel to train an SVM classifier, but it appears to underfit the\n",
        "training collection. Is it better to raise or lower (gamma)? What about the letter C?**"
      ],
      "metadata": {
        "id": "u1FbpBTZwwiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If an SVM classifier that uses an RBF kernel appears to underfit the training collection, then there are a few things that can be done to try to improve the fit.\n",
        "\n",
        "One option is to raise the value of the gamma parameter. **Gamma controls the width of the RBF kernel, and a larger value will result in a narrower kernel, which can lead to a more complex decision boundary.** However, a very high value of gamma can lead to overfitting, so it's important to find the right balance.\n",
        "\n",
        "Another option is to lower the value of the C parameter. **C is a regularization parameter that controls the trade-off between maximizing the margin and minimizing the misclassification error.** A lower value of C will result in a larger margin and a less complex decision boundary, but it may also result in more misclassifications.\n",
        "\n",
        "It's worth noting that changing these parameters will affect the performance of the model differently depending on the dataset, so it's important to try different values and evaluate the performance of the model to find the optimal values.\n",
        "\n",
        "In summary, if the SVM underfits the training collection, it is likely that a larger value of gamma and a smaller value of C will help to improve the fit."
      ],
      "metadata": {
        "id": "EqdCEnYWw2d7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pG75t5FFtJ_X"
      },
      "outputs": [],
      "source": []
    }
  ]
}