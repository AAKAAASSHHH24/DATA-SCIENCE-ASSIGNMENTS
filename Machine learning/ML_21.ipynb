{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is the estimated depth of a Decision Tree trained (unrestricted) on a one million instance\n",
        "training set?**\n"
      ],
      "metadata": {
        "id": "5qb7_3ox4Bz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The depth of a Decision Tree is determined by the number of splits or \"levels\" in the tree. The maximum depth of a tree trained on a one million instance training set would depend on the complexity of the dataset and the stopping criteria used during training. Without more information, it is not possible to provide an estimate."
      ],
      "metadata": {
        "id": "lT1kHrPi4Sgp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Is the Gini impurity of a node usually lower or higher than that of its parent? Is it always\n",
        "lower/greater, or is it usually lower/greater?**\n"
      ],
      "metadata": {
        "id": "qx7xDXQ04Hq7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Gini impurity of a node is a measure of the homogeneity of the instances in that node, with 0 indicating perfect homogeneity (all instances belong to the same class) and 1 indicating perfect heterogeneity (the instances belong to all possible classes with equal probability). The Gini impurity of a node is usually lower than that of its parent because the goal of the tree-building algorithm is to create splits that result in more homogeneous subsets. However, it is not always lower because the Gini impurity depends on the split that is chosen, and it is possible for a split to lead to a higher impurity in the child node."
      ],
      "metadata": {
        "id": "djqPoKSY4Wki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Explain if its a good idea to reduce max depth if a Decision Tree is overfitting the training set?**"
      ],
      "metadata": {
        "id": "Ha-PAgOu4MJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reducing the max depth of a Decision Tree can be a good idea if the tree is overfitting the training set. Overfitting occurs when a model is too complex and has \"memorized\" the training data, leading to poor generalization performance on unseen data. Reducing the max depth of the tree can prevent overfitting by limiting the number of splits and simplifying the tree, thus making it more generalizable. However, reducing the max depth too much may lead to underfitting, where the model is not complex enough to capture the underlying patterns in the data."
      ],
      "metadata": {
        "id": "IVWPHAVU4a0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Explain if its a good idea to try scaling the input features if a Decision Tree underfits the training\n",
        "set?**\n"
      ],
      "metadata": {
        "id": "7_fhUIEz4wzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling the input features of a Decision Tree will not have an effect on underfitting. Scaling is a technique used to standardize the range of input variables, which can be useful in some algorithms that are sensitive to the scale of the input, like some linear models and neural networks. Decision Trees are not sensitive to the scale of the input, thus scaling the input features will not improve the performance of an underfitting Decision Tree. To improve the performance of an underfitting Decision Tree, one could try increasing the depth of the tree, increasing the number of splits, or increasing the complexity of the tree by adding more features or increasing the number of instances in the training set."
      ],
      "metadata": {
        "id": "kf5Sno5747e-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. How much time will it take to train another Decision Tree on a training set of 10 million instances\n",
        "if it takes an hour to train a Decision Tree on a training set with 1 million instances?**"
      ],
      "metadata": {
        "id": "FMR6PBXP423q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a Decision Tree on a dataset of 10 million instances will take approximately 10 times longer than training a Decision Tree on a dataset of 1 million instances, assuming that the time complexity of the algorithm is linear with respect to the number of instances. So it would take about 10 hours to train a Decision Tree on a dataset of 10 million instances if it takes 1 hour to train a Decision Tree on a dataset of 1 million instances. However, this is an approximation and the actual time required will depend on the complexity of the dataset, the algorithm and hardware configuration.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-KoKvVk44_gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Will setting presort=True speed up training if your training set has 100,000 instances?**"
      ],
      "metadata": {
        "id": "I6je3Inb5416"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The parameter presort controls whether the algorithm should presort the data before building the tree. The presort option can speed up training if the training set is large and not already sorted, as it can reduce the number of times the data needs to be searched during the training process. However, the effect of presort on training time will depend on the size and complexity of the dataset, the algorithm, and the hardware configuration.\n",
        "In general, the larger the dataset, the more beneficial it is to set presort=True, as it can help to reduce the complexity of the algorithm. If your training set has 100,000 instances, setting presort=True could speed up training, but it will also depend on the specific dataset and the hardware used. If you have a large dataset, it's worth experimenting with presort=True and comparing the training time with and without it to see if it's beneficial for your specific use case."
      ],
      "metadata": {
        "id": "1ebDCooC6Giy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ-8cdJtyRGs"
      },
      "outputs": [],
      "source": []
    }
  ]
}