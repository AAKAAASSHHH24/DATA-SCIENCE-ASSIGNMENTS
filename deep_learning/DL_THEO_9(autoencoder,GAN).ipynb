{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. What are the main tasks that autoencoders are used for?**\n"
      ],
      "metadata": {
        "id": "JYFcdty-F7-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoencoders are mainly used for:\n",
        "\n",
        "Data compression and dimensionality reduction\n",
        "\n",
        "Anomaly detection\n",
        "\n",
        "Data generation\n",
        "\n",
        "Pretraining for supervised learning\n",
        "\n",
        "\n",
        "**Autoencoder network is composed of two parts Encoder and Decoder.**\n",
        "\n",
        "Encoder : This part of the network encodes or compresses the input data into a latent-space representation. The compressed data typically looks garbled, nothing like the original data.\n",
        "\n",
        "Decoder : This part of network decodes or reconstructs the encoded data(latent space representation) back to original dimension. The decoded data is a lossy reconstruction of the original data.\n",
        "\n",
        "Purpose of autoencoders in not to copy inputs to outputs, but to train autoencoders to copy inputs to outputs in such a way that bottleneck will learn useful information or properties.\n",
        "\n",
        "We can make out latent space representation learn useful features by giving it smaller dimensions then input data. In this case autoencoder is undercomplete. By training an undercomplete representation, we force the autoencoder to learn the most salient features of the training data."
      ],
      "metadata": {
        "id": "sphpJXU3GFvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![autoencoder.webp](data:image/webp;base64,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)"
      ],
      "metadata": {
        "id": "w6PLiFGlHBTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Suppose you want to train a classifier, and you have plenty of unlabeled training data but\n",
        "only a few thousand labeled instances. How can autoencoders help? How would you\n",
        "proceed?**"
      ],
      "metadata": {
        "id": "V5oFqjoQF_03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoencoders can help in the following ways:\n",
        "\n",
        "Pretraining: \n",
        "\n",
        "Autoencoders can be used to pretrain a classifier in a self-supervised manner. The autoencoder can be trained on the large unlabeled dataset to learn a compact representation of the data. Then, the trained autoencoder can be used as the input layer to a supervised classifier, which can be trained on the smaller labeled dataset to improve performance.\n",
        "Data augmentation: Autoencoders can be used to generate new training examples from the available data, allowing the classifier to learn from more examples, even if they are not labeled.\n",
        "\n",
        "Semi-supervised learning:\n",
        "\n",
        "Autoencoders can be used in a semi-supervised manner, where the autoencoder is trained on both the labeled and unlabeled data. This can improve performance by leveraging the large amount of unlabeled data.\n",
        "To proceed, one could:\n",
        "\n",
        "Train an autoencoder on the large unlabeled dataset to learn a compact representation of the data.\n",
        "Use the trained autoencoder to transform the data into a lower-dimensional representation, which can be used as the input layer to a supervised classifier.\n",
        "Train the classifier on the small labeled dataset, using the representations learned by the autoencoder as input.\n",
        "Optionally, use the autoencoder in a semi-supervised manner to further improve performance."
      ],
      "metadata": {
        "id": "FnIvFiDVGgdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. If an autoencoder perfectly reconstructs the inputs, is it necessarily a good autoencoder?\n",
        "How can you evaluate the performance of an autoencoder?**\n"
      ],
      "metadata": {
        "id": "dQmXyekyHGIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A perfect reconstruction of inputs does not necessarily indicate that an autoencoder is a good autoencoder. While reconstruction accuracy is an important metric, it is not the only one. **Other important factors to consider include the ability of the autoencoder to capture the underlying structure of the data**, the computational efficiency of the autoencoder, and the quality of the learned representations for tasks such as data generation or dimensionality reduction.\n",
        "\n",
        "To evaluate the performance of an autoencoder, **various metrics** can be used, including:\n",
        "\n",
        "Reconstruction error: \n",
        "\n",
        "The average difference between the input and reconstructed data.\n",
        "\n",
        "Latent space quality:\n",
        "\n",
        " The ability of the autoencoder to capture the underlying structure of the data in the lower-dimensional latent space. This can be evaluated by clustering the data in the latent space and examining the quality of the resulting clusters.\n",
        "\n",
        "Generative quality: \n",
        "\n",
        "The ability of the autoencoder to generate new, plausible examples. This can be evaluated by comparing generated examples to real examples and evaluating their similarity."
      ],
      "metadata": {
        "id": "QjHW_jYYHQFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. What are undercomplete and overcomplete autoencoders? What is the main risk of an\n",
        "excessively undercomplete autoencoder? What about the main risk of an overcomplete\n",
        "autoencoder?**"
      ],
      "metadata": {
        "id": "3KG0MVFoHLIE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Undercomplete and overcomplete autoencoders:\n",
        "\n",
        "An undercomplete autoencoder is an autoencoder with a bottleneck architecture, where the number of neurons in the bottleneck layer is less than the number of neurons in the input layer. This architecture encourages the autoencoder to learn a compact representation of the data, as the bottleneck layer acts as a constraint on the amount of information that can be stored in the hidden layer.\n",
        "The main risk of an excessively undercomplete autoencoder is that it may not be able to capture the complexity of the data. If the bottleneck layer is too small, the autoencoder may not be able to learn a sufficiently rich representation of the data, resulting in poor performance for tasks such as data generation or dimensionality reduction.\n",
        "\n",
        "An overcomplete autoencoder, on the other hand, is an autoencoder with a bottleneck layer that has more neurons than the input layer. This architecture provides more flexibility for the autoencoder to learn a rich representation of the data, but can also result in overfitting to the training data.\n",
        "\n",
        "The main risk of an overcomplete autoencoder is overfitting to the training data. With more neurons in the bottleneck layer than in the input layer, the autoencoder has more capacity to model the training data, which can result in poor generalization performance on unseen data."
      ],
      "metadata": {
        "id": "pQVo9XsiHx3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. How do you tie weights in a stacked autoencoder? What is the point of doing so?**\n"
      ],
      "metadata": {
        "id": "irB4Hr6II0A6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tying weights in a stacked autoencoder refers to reusing the same weights in the encoding and decoding parts of the autoencoder. The point of tying weights is to enforce the constraint that the encoding and decoding operations are inverse operations of each other. This can help the autoencoder learn more robust representations, as it forces the hidden layer to contain a compact and meaningful representation of the data."
      ],
      "metadata": {
        "id": "bTqW9XspJDCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What is a generative model? Can you name a type of generative autoencoder?**"
      ],
      "metadata": {
        "id": "tPeDCrTdI790"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A generative model is a type of machine learning model that is trained to generate new, plausible examples of data. The main goal of a generative model is to learn the distribution of a given dataset, and then generate new examples that are similar to the training data.\n",
        "\n",
        "One type of generative autoencoder is a Variational Autoencoder (VAE). A VAE is a generative model that uses an encoder-decoder architecture, where the encoder maps the input data to a lower-dimensional representation (latent space), and the decoder maps the latent space back to the original data. The VAE is trained to maximize the likelihood of the training data given the latent space, which allows the model to generate new, plausible examples of the data."
      ],
      "metadata": {
        "id": "cf73LqMDJHmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What is a GAN? Can you name a few tasks where GANs can shine?**\n"
      ],
      "metadata": {
        "id": "J6vI-bj7Jrow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Generative Adversarial Network (GAN) is a type of generative model that consists of two neural networks: \n",
        "\n",
        "a generator and a discriminator. \n",
        "\n",
        "The generator is trained to generate new, plausible examples of data, while the discriminator is trained to distinguish between real and generated examples. The two networks are trained together in an adversarial manner, with the generator attempting to fool the discriminator and the discriminator trying to correctly identify the generated examples.\n",
        "Tasks where GANs can shine include:\n",
        "\n",
        "Image generation: GANs have been used to generate realistic images of objects, faces, and landscapes.\n",
        "\n",
        "Style transfer: GANs can be used to transfer the style of one image to another.\n",
        "\n",
        "Data augmentation: GANs can be used to generate new, synthetic examples of data that can be used to augment the training set for other machine learning models."
      ],
      "metadata": {
        "id": "tusKLDejJ0BW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. What are the main difficulties when training GANs?**"
      ],
      "metadata": {
        "id": "5kod5xwXJvAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training GANs can be difficult due to the following challenges:\n",
        "\n",
        "Stability of training: GANs are known to be difficult to train, as the generator and discriminator can easily get stuck in a suboptimal state, leading to mode collapse or other stability issues.\n",
        "\n",
        "sensitivity to hyperparameters: GANs are highly sensitive to the choice of hyperparameters, such as the learning rate and network architecture, which can affect the stability of training and the quality of the generated examples.\n",
        "\n",
        "difficulty in evaluating the quality of generated examples: Unlike traditional machine learning models, it can be difficult to objectively evaluate the quality of generated examples, as there is no direct measure of how well the model has captured the underlying distribution of the data.\n",
        "\n",
        "overfitting: GANs can overfit to the training data, especially when the training set is small or limited in diversity."
      ],
      "metadata": {
        "id": "ScZWUcviKDB1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ0WMYmpFc2J"
      },
      "outputs": [],
      "source": []
    }
  ]
}