{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. What are the advantages of a CNN over a fully connected DNN for image classification?**"
      ],
      "metadata": {
        "id": "EJly6Fvz9pTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Neural Networks (CNNs) are well-suited for image classification tasks as they have several advantages over fully connected Deep Neural Networks (DNNs):\n",
        "\n",
        "Spatial Invariance: CNNs use convolutional layers with filters to detect patterns and features in images, making them more robust to local translations and deformations in the image. This makes them better suited for image classification tasks where the same object may appear in different positions or orientations within the image.\n",
        "\n",
        "Parameter Efficiency: CNNs have significantly fewer parameters than fully connected DNNs, making them more computationally efficient and easier to train.\n",
        "\n",
        "Feature Reuse: In CNNs, the same features can be learned and applied to different parts of the image through pooling layers. This allows for feature reuse and reduces the number of parameters required, making the network more computationally efficient.\n",
        "\n",
        "Robustness to Scale and Translation: CNNs use pooling layers to reduce the spatial dimensions of the input, making them more robust to small variations in scale and translation.\n",
        "\n",
        "Better Handling of Local Context: Convolutional layers in CNNs scan the image using filters and pooling layers, allowing them to preserve the local context of the image and better learn the fine-grained details that are important for image classification.\n",
        "\n",
        "In conclusion, the convolutional structure of CNNs, with their ability to detect patterns and features, handle local context, and reduce parameters, make them well-suited for image classification tasks."
      ],
      "metadata": {
        "id": "ywbsFyXs91q-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Consider a CNN composed of three convolutional layers, each with 3 × 3 kernels, a stride of\n",
        "2, and &quot;same&quot; padding. The lowest layer outputs 100 feature maps, the middle one outputs\n",
        "200, and the top one outputs 400. The input images are RGB images of 200 × 300 pixels.\n",
        "What is the total number of parameters in the CNN? If we are using 32-bit floats, at least how much\n",
        "RAM will this network require when making a prediction for a single instance? What about when\n",
        "training on a mini-batch of 50 images?**"
      ],
      "metadata": {
        "id": "Iwnmkb6J-WaZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To calculate the total number of parameters in the CNN, we need to consider the parameters in each convolutional layer. Each 3x3 kernel in a convolutional layer has 9 parameters, and each feature map in a layer has a separate set of parameters.\n",
        "\n",
        "The first layer has 100 feature maps and each feature map has 9 parameters, so the first layer has 9 * 100 = 900 parameters.\n",
        "\n",
        "The second layer has 200 feature maps and each feature map has 9 parameters, so the second layer has 9 * 200 = 1800 parameters.\n",
        "\n",
        "The third layer has 400 feature maps and each feature map has 9 parameters, so the third layer has 9 * 400 = 3600 parameters.\n",
        "\n",
        "So the total number of parameters in the CNN is 900 + 1800 + 3600 = 5400.\n",
        "\n",
        "For a single prediction on a 200x300 RGB image, the network would need to store the activations of each feature map for each layer. Each pixel in an RGB image has 3 values, so a 200x300 image has 200 * 300 * 3 = 180000 values. After the first layer, the activations will be 100 feature maps of size 100x150, the second layer will produce 200 feature maps of size 50x75, and the final layer will produce 400 feature maps of size 25x38.\n",
        "\n",
        "Therefore, the memory required for a single prediction is (180000 * 4 + 100 * 100 * 150 * 4 + 200 * 50 * 75 * 4 + 400 * 25 * 38 * 4) bytes = approximately 2.6 GB, where 4 bytes are required to store a 32-bit float.\n",
        "\n",
        "For a mini-batch of 50 images, the memory required would be approximately 2.6 GB * 50 = 130 GB."
      ],
      "metadata": {
        "id": "Nm3zaapv-m9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. If your GPU runs out of memory while training a CNN, what are five things you could try to\n",
        "solve the problem?**"
      ],
      "metadata": {
        "id": "8JH0RGX0_KwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduce the batch size: Decreasing the number of samples in each batch can reduce the memory requirements.\n",
        "\n",
        "Use model pruning techniques: Removing unimportant weights and neurons can reduce the overall memory footprint of the model.\n",
        "\n",
        "Use lower-precision data types: Using lower-precision data types such as float16 instead of float32 can significantly reduce memory usage.\n",
        "\n",
        "Reduce the size of input images: Decreasing the resolution of the input images can reduce memory requirements.\n",
        "\n",
        "Use Gradient Checkpointing: By saving intermediate activations during forward pass and not storing all activations in memory, you can reduce memory usage."
      ],
      "metadata": {
        "id": "Tv8uYYfc_H1-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Why would you want to add a max pooling layer rather than a convolutional layer with the\n",
        "same stride?**"
      ],
      "metadata": {
        "id": "atLF5hUN_cDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max pooling and convolutional layers serve different purposes and have different effects on the feature maps.\n",
        "\n",
        "Max pooling is used for down-sampling, it reduces the spatial dimensions of the feature map by taking the maximum value over a local neighborhood. This has the effect of reducing the computational complexity and allowing the model to focus on the most important features.\n",
        "\n",
        "Convolutional layers, on the other hand, are used for feature extraction, they learn local patterns in the input data and increase the depth of the feature map by applying filters.\n",
        "\n",
        "Using a convolutional layer with the same stride as a max pooling layer would simply reduce the spatial dimensions of the feature map, but it would not reduce the computational complexity or allow the model to focus on the most important features.\n",
        "\n",
        "In summary, max pooling is used for down-sampling, while convolutional layers are used for feature extraction, adding a max pooling layer allows for the reduction of computational complexity and focuses on important features."
      ],
      "metadata": {
        "id": "cXM9GCYm_mpq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. When would you want to add a local response normalization layer?**"
      ],
      "metadata": {
        "id": "-ILuOzT8_uCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Local Response Normalization (LRN) is a normalization technique used to normalize the activations within a local neighborhood in the same channel. It was originally introduced in the AlexNet architecture to address the problem of internal covariate shift, which occurs when the distribution of the activations changes during training.\n",
        "\n",
        "The LRN layer acts as a form of data-dependent regularization, which helps to mitigate the internal covariate shift and reduce overfitting. It has been shown to improve the performance of Convolutional Neural Networks (CNNs) on image classification tasks.\n",
        "\n",
        "In summary, you would want to add a LRN layer when training a CNN for image classification and you are experiencing internal covariate shift and overfitting problems."
      ],
      "metadata": {
        "id": "VJYEEDXW_7lB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Can you name the main innovations in AlexNet, compared to LeNet-5? What about the main\n",
        "innovations in GoogLeNet, ResNet, SENet, and Xception?**"
      ],
      "metadata": {
        "id": "_yUNA1kNAJSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AlexNet** is a deep Convolutional Neural Network (CNN) architecture introduced in 2012 and won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) that year. The main innovations in AlexNet compared to LeNet-5 (a previous architecture introduced in the 90s) are:\n",
        "\n",
        "Increased Depth: AlexNet has eight layers compared to LeNet-5's seven layers.\n",
        "\n",
        "Large Number of Filters: AlexNet uses many more filters, increasing the capacity to learn complex features.\n",
        "\n",
        "ReLU Activations: AlexNet introduced the use of Rectified Linear Unit (ReLU) activation functions, which have proven to be more effective than traditional sigmoidal activation functions.\n",
        "\n",
        "Dropout Regularization: AlexNet introduced the use of dropout regularization to prevent overfitting.\n",
        "\n",
        "**GoogLeNet** is a deep CNN architecture introduced in 2014, the main innovations in GoogLeNet compared to AlexNet are:\n",
        "\n",
        "Inception Modules: GoogLeNet introduced the use of Inception modules, which allows for a more efficient use of computational resources by applying multiple filters in parallel and concatenating their outputs.\n",
        "\n",
        "Improved Network Depth: GoogLeNet has 22 layers, compared to AlexNet's eight layers.\n",
        "\n",
        "**ResNet** is a deep residual network introduced in 2015, the main innovations in ResNet compared to GoogLeNet and AlexNet are:\n",
        "\n",
        "Residual Connections: ResNet introduced the use of residual connections, which allow the network to learn residual functions with reference to the input, instead of learning the input itself.\n",
        "\n",
        "Extreme Depth: ResNet's architecture allows for training extremely deep networks, with over 150 layers.\n",
        "\n",
        "**SENet is a deep CNN architecture introduced in 2017, the main innovations in SENet compared to ResNet are:**\n",
        "\n",
        "Squeeze-and-Excitation (SE) Blocks: SENet introduced the use of Squeeze-and-Excitation (SE) blocks, which allow the network to adaptively re-calibrate channel-wise feature responses by explicitly modeling inter-dependencies between channels.\n",
        "\n",
        "**Xception is a deep CNN architecture introduced in 2016, the main innovations in Xception compared to ResNet are:**\n",
        "\n",
        "Depthwise Separable Convolutions: Xception introduced the use of depthwise separable convolutions, which allow for a more efficient use of computational resources and reduced overfitting.\n",
        "\n",
        "Extremely Deep and Narrow: Xception's architecture is extremely deep and narrow, with a depth of 126 layers and a reduced number of filters compared to ResNet."
      ],
      "metadata": {
        "id": "f511q1XwAhDu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. What is a fully convolutional network? How can you convert a dense layer into a\n",
        "convolutional layer?**"
      ],
      "metadata": {
        "id": "jLw3i8hHBjub"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A fully convolutional network (FCN) is a type of Convolutional Neural Network (CNN) where the fully connected (dense) layers of a traditional CNN have been replaced by 1x1 convolutional layers. This allows the network to operate on inputs of arbitrary size and preserve spatial information, making it suitable for tasks such as semantic segmentation, object detection, and image generation.\n",
        "\n",
        "To convert a dense layer into a convolutional layer, the dense layer needs to be transformed into a 1x1 convolutional layer. This can be achieved by changing the dense layer's weights into a kernel and stride of 1, then adding a padding of 0. The dense layer's activation function should also be replaced with an activation function suitable for convolutional layers, such as ReLU.\n",
        "\n",
        "The conversion of a dense layer to a 1x1 convolutional layer effectively maintains the dense layer's functionality while preserving the spatial information in the feature maps, allowing the network to be used for tasks that require spatial information."
      ],
      "metadata": {
        "id": "1z6Y2-jGBrQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. What is the main technical difficulty of semantic segmentation?**"
      ],
      "metadata": {
        "id": "280AgGw4B8vR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main technical difficulty of semantic segmentation is obtaining dense, per-pixel predictions for the entire image while preserving spatial information. This is challenging because it requires the network to have a large enough receptive field to capture long-range dependencies while still being able to make precise per-pixel predictions. Additionally, semantic segmentation models must also deal with class imbalance and the presence of small, meaningful objects, which can be difficult to detect and segment.\n",
        "\n",
        "Another challenge in semantic segmentation is the need for large amounts of annotated training data, which can be time-consuming and expensive to obtain. The model also needs to be able to generalize well to unseen images and maintain a good balance between precision and recall.\n",
        "\n",
        "To overcome these difficulties, many recent advances in semantic segmentation make use of techniques such as multi-scale prediction, context aggregation, and class-balanced loss functions. Additionally, pre-training on large-scale classification tasks and using data augmentation can help improve performance."
      ],
      "metadata": {
        "id": "VKmGpCBACD38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST.**"
      ],
      "metadata": {
        "id": "dC8i8kCvCYBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Reshape the data\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# Build the model\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8W1KgBtDOXY",
        "outputId": "fb4a20e2-cb49-4a29-c17b-59df939110ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1438 - accuracy: 0.9575\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0503 - accuracy: 0.9847\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.0317 - accuracy: 0.9897\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.0226 - accuracy: 0.9926\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0154 - accuracy: 0.9951\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0099 - accuracy: 0.9969\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.0085 - accuracy: 0.9974\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0069 - accuracy: 0.9977\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.0050 - accuracy: 0.9984\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.0046 - accuracy: 0.9986\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0578 - accuracy: 0.9871\n",
            "Test accuracy: 0.9871000051498413\n"
          ]
        }
      ]
    }
  ]
}