{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. How would you describe TensorFlow in a short sentence? What are its main features? Can\n",
        "you name other popular Deep Learning libraries?**"
      ],
      "metadata": {
        "id": "h_cMPvRTvzLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow is an open-source software library for dataflow and differentiable programming across a range of tasks. It's main features include support for both training and inference of deep learning models, scalability, and a vast ecosystem of tools and libraries. Other popular deep learning libraries include PyTorch, Caffe, and Keras."
      ],
      "metadata": {
        "id": "SeQyoIWpv-Yu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Is TensorFlow a drop-in replacement for NumPy? What are the main differences between\n",
        "the two?**\n"
      ],
      "metadata": {
        "id": "UCPlRCrRwK_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, TensorFlow is not a drop-in replacement for NumPy. While TensorFlow does have functionality similar to NumPy, it also provides additional functionality specifically designed for deep learning such as automatic differentiation and GPU acceleration.\n",
        "\n",
        "NumPy is a library for numerical computations, including support for a powerful N-dimensional array object, while TensorFlow is a platform for building and training machine learning models. The main difference is that TensorFlow is geared towards large-scale numerical computations, specifically for deep learning, while NumPy is a more general-purpose numerical computation library."
      ],
      "metadata": {
        "id": "eodtkoQuwP50"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?**"
      ],
      "metadata": {
        "id": "GKbm1BU9xanx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, the results of tf.range(10) and tf.constant(np.arange(10)) are not the same.\n",
        "\n",
        "tf.range(10) generates a tensor with values ranging from 0 to 9, while tf.constant(np.arange(10)) creates a constant tensor with the same values, but represented as a NumPy array first and then converted to a TensorFlow tensor.\n",
        "\n",
        "A constant tensor is a TensorFlow tensor with a fixed value that cannot be changed during the course of a TensorFlow computation. It is created using the tf.constant function, which takes a value as an argument and returns a tensor with that value.\n",
        "\n",
        "Constant tensors are useful when you have fixed data that you want to use in your TensorFlow computation, such as a set of weights for a machine learning model.\n",
        "\n",
        "So while the values contained in the tensors are the same, they are not necessarily the same TensorFlow objects."
      ],
      "metadata": {
        "id": "JJzTc35Txepu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMe8jkUCvDM1",
        "outputId": "dfc84b4f-a2d3-47e1-9338-11601bee02fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "tf.constant(np.arange(10))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.range(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKXqva0lyUv9",
        "outputId": "e083916b-3bbb-42cf-c069-a913e52bdd6d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Can you name six other data structures available in TensorFlow, beyond regular tensors?**"
      ],
      "metadata": {
        "id": "WryN9DQezy0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, beyond regular tensors, TensorFlow provides several other data structures that can be used for various purposes. Here are six examples:\n",
        "\n",
        "*tf.Variable:* A TensorFlow variable is a type of tensor that can be changed during the course of a TensorFlow computation. It is useful for storing and updating parameters, such as weights in a machine learning model.\n",
        "\n",
        "*tf.SparseTensor:* A sparse tensor is a TensorFlow tensor with sparse values, where only a small fraction of the values are non-zero. Sparse tensors are useful for representing large tensors with many zeros, as they can be stored and processed more efficiently.\n",
        "\n",
        "tf.RaggedTensor: A ragged tensor is a TensorFlow tensor with variable-length slices, where each row in the tensor has a different length. Ragged tensors are useful for representing sequences of variable length, such as sequences of words in a document.\n",
        "\n",
        "tf.TensorArray: A TensorFlow tensor array is a data structure that allows you to store and manipulate a dynamically-sized list of tensors. It is useful for implementing dynamic control flow, where the number of operations to be performed is not known ahead of time.\n",
        "\n",
        "tf.data.Dataset: A TensorFlow dataset is a data structure for representing a sequence of elements, which can be transformed and processed using the tf.data API. It is useful for efficiently processing large amounts of data, as it can be easily parallelized and batched for training deep learning models.\n",
        "\n",
        "tf.Queue: A TensorFlow queue is a data structure for holding a list of tensors that can be added to and retrieved from by multiple parallel operations. Queues are useful for implementing multi-producer, multi-consumer pipelines, where data is passed from one operation to the next in parallel."
      ],
      "metadata": {
        "id": "YqmHUAGp0B2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. A custom loss function can be defined by writing a function or by subclassing\n",
        "the keras.losses.Loss class. When would you use each option?**"
      ],
      "metadata": {
        "id": "HNVsT9qf010g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A custom loss function can be defined in TensorFlow by either writing a function or subclassing the keras.losses.Loss class. The choice of which option to use depends on the specific requirements of the custom loss function.\n",
        "\n",
        "Writing a function is the simplest and most straightforward approach when the custom loss function is relatively simple and does not require any additional state to be maintained. For example, if the custom loss function is just a mathematical expression that takes two tensors as inputs and returns a scalar, it can be easily defined as a standalone function."
      ],
      "metadata": {
        "id": "mduQpDdB0-9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss(y_true, y_pred):\n",
        "  return tf.reduce_mean(tf.square(y_true - y_pred))\n"
      ],
      "metadata": {
        "id": "XbEDEySwyasm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the other hand, subclassing the keras.losses.Loss class is a more advanced approach that is useful when the custom loss function requires additional state or has a more complex implementation. For example, if the custom loss function requires additional information, such as the number of positive samples in a batch, or if it requires custom logic for handling NaN or inf values, it is more convenient to define the custom loss function as a subclass of keras.losses.Loss."
      ],
      "metadata": {
        "id": "-9ZCfCBV1GsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "class CustomLoss(keras.losses.Loss):\n",
        "  def __init__(self, positive_weights, name='custom_loss'):\n",
        "    super(CustomLoss, self).__init__(name=name)\n",
        "    self.positive_weights = positive_weights\n",
        "\n",
        "  def call(self, y_true, y_pred):\n",
        "    return tf.reduce_mean(self.positive_weights * tf.square(y_true - y_pred))\n"
      ],
      "metadata": {
        "id": "49YXlcd91DAQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In summary, if the custom loss function is relatively simple and can be defined as a mathematical expression, it is better to define it as a standalone function. If the custom loss function is more complex and requires additional state or custom logic, it is better to define it as a subclass of keras.losses.Loss."
      ],
      "metadata": {
        "id": "W1ONFZo41fnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. Similarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric.\n",
        "When would you use each option?**"
      ],
      "metadata": {
        "id": "IaIHajX42xPZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A custom metric can be defined in TensorFlow by either writing a function or subclassing the keras.metrics.Metric class. The choice of which option to use depends on the specific requirements of the custom metric.\n",
        "\n",
        "Writing a function is the simplest and most straightforward approach when the custom metric is relatively simple and does not require any additional state to be maintained. For example, if the custom metric is just a mathematical expression that takes two tensors as inputs and returns a scalar, it can be easily defined as a standalone function."
      ],
      "metadata": {
        "id": "ADE3IquX218l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_metric(y_true, y_pred):\n",
        "  return tf.reduce_mean(tf.abs(y_true - y_pred))\n"
      ],
      "metadata": {
        "id": "9lLuS3gZ1KFA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the other hand, subclassing the keras.metrics.Metric class is a more advanced approach that is useful when the custom metric requires additional state or has a more complex implementation. For example, if the custom metric requires multiple updates over multiple batches of data, or if it requires custom logic for handling NaN or inf values, it is more convenient to define the custom metric as a subclass of keras.metrics.Metric."
      ],
      "metadata": {
        "id": "desKp0RD3ABh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMetric(keras.metrics.Metric):\n",
        "  def __init__(self, name='custom_metric', **kwargs):\n",
        "    super(CustomMetric, self).__init__(name=name, **kwargs)\n",
        "    self.total = self.add_weight(name='total', initializer='zeros')\n",
        "    self.count = self.add_weight(name='count', initializer='zeros')\n",
        "\n",
        "  def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "    y_diff = tf.abs(y_true - y_pred)\n",
        "    self.total.assign_add(tf.reduce_sum(y_diff))\n",
        "    self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
        "\n",
        "  def result(self):\n",
        "    return self.total / self.count\n"
      ],
      "metadata": {
        "id": "wHGVB14w28jj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In summary, if the custom metric is relatively simple and can be defined as a mathematical expression, it is better to define it as a standalone function. If the custom metric is more complex and requires additional state or custom logic, it is better to define it as a subclass of keras.metrics.Metric."
      ],
      "metadata": {
        "id": "mQ_iHqB93JQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. When should you create a custom layer versus a custom model?**\n"
      ],
      "metadata": {
        "id": "q2TveUG33khd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow provides a number of built-in layers for common deep learning tasks, such as dense, convolutional, and recurrent layers. However, sometimes you may need to implement a custom layer to perform a specific task that is not covered by the built-in layers. In this case, you should create a custom layer.\n",
        "A custom layer is a good choice when you want to implement a simple operation that can be expressed as a matrix operation, such as a dot product or a convolution. You can create a custom layer by subclassing the keras.layers.Layer class and implementing the call method, which specifies the forward pass of the layer.\n",
        "\n",
        "On the other hand, a custom model is a more advanced option that is useful when you want to build a more complex neural network architecture that cannot be expressed as a sequence of built-in layers. A custom model is defined by subclassing the keras.Model class and implementing the call method, which specifies the forward pass of the entire model."
      ],
      "metadata": {
        "id": "vXWR2KHM3uJZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. When should you create a custom layer versus a custom model?\n",
        "**8. What are some use cases that require writing your own custom training loop?**"
      ],
      "metadata": {
        "id": "ha40oCTl3nw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In some cases, you may want to customize the training process in a way that cannot be achieved using the built-in training loops provided by TensorFlow. For example, you may want to implement a custom training algorithm, or you may want to train multiple models in parallel. In these cases, you can write your own custom training loop by manually specifying the forward and backward passes for the model.\n",
        "A custom training loop can be useful in several scenarios, including:\n",
        "\n",
        "Implementing custom training algorithms that are not covered by the built-in training loops, such as reinforcement learning or generative adversarial networks.\n",
        "Debugging and profiling the training process to understand what is happening inside the model and identify bottlenecks or performance issues.\n",
        "Training multiple models in parallel, either on multiple GPUs or on a distributed computing infrastructure.\n",
        "Incorporating additional logic into the training process, such as early stopping or custom learning rate schedules.\n",
        "Note that writing a custom training loop can be complex and error-prone, so it is usually only recommended for advanced users or when there is a specific need that cannot be satisfied by the built-in training loops."
      ],
      "metadata": {
        "id": "EUREJ05v34JC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Can custom Keras components contain arbitrary Python code, or must they be convertible to\n",
        "TF Functions?**\n"
      ],
      "metadata": {
        "id": "d2T1BPem4HQL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom Keras components, such as custom layers and custom models, must be convertible to TensorFlow Functions in order to be used in a TensorFlow computation. This means that the computations performed by the custom component must be expressible using TensorFlow operations, and the component must be able to take and return TensorFlow tensors. While custom components can contain arbitrary Python code, this code must be used to perform operations that can be expressed using TensorFlow operations."
      ],
      "metadata": {
        "id": "cNic-MJz4Xxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. What are the main rules to respect if you want a function to be convertible to a TF Function?**\n"
      ],
      "metadata": {
        "id": "IS2OPhJn4KlP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to be convertible to a TensorFlow Function, a custom Keras component must follow the following rules:\n",
        "\n",
        "The component must take and return TensorFlow tensors, not numpy arrays or other Python data structures.\n",
        "The computations performed by the component must be expressible using TensorFlow operations, and the component must not use any external libraries or Python modules that cannot be expressed in TensorFlow.\n",
        "The component must be compatible with TensorFlow's automatic differentiation system, so that the gradients of the computations performed by the component can be computed automatically."
      ],
      "metadata": {
        "id": "3glelPsk4bZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. When would you need to create a dynamic Keras model? How do you do that? Why not\n",
        "make all your models dynamic?**"
      ],
      "metadata": {
        "id": "Kl6veIfL4QE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A dynamic Keras model is a model that allows you to change its architecture during runtime, for example by adding or removing layers. This can be useful when you need to create a model that can adapt to different inputs, or when you want to build a model with a variable number of layers or neurons.\n",
        "To create a dynamic Keras model, you can use the functional API, which allows you to build models by defining a directed acyclic graph of layers. In a dynamic model, you can build the graph incrementally, adding or removing layers as needed.\n",
        "\n",
        "It is not necessary to make all models dynamic, as dynamic models are more complex to implement and can be slower than static models. However, dynamic models can be useful in specific scenarios where you need the flexibility to change the model architecture during runtime.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PMoHNJVG4e00"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wG_XG5HW3FCO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}