{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**2. What are the different types of activation functions popularly used? Explain each of them.**"
      ],
      "metadata": {
        "id": "Vu2VRdJk5en2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several activation functions that are commonly used in deep learning, including:\n",
        "\n",
        "Sigmoid: This activation function maps any input to the range of 0 and 1, outputting a probability value that represents the likelihood of a particular event.\n",
        "\n",
        "ReLU (Rectified Linear Unit): This activation function replaces all negative values in the input with zero and leaves all positive values unchanged. It is computationally efficient and widely used in feedforward neural networks.\n",
        "\n",
        "Tanh (Hyperbolic Tangent): This activation function maps inputs to values in the range of -1 and 1. It is often used in recurrent neural networks (RNNs) where the output must be centered around zero.\n",
        "\n",
        "Softmax: This activation function is used for multiclass classification problems, mapping a vector of real values to a probability distribution over several classes.\n",
        "\n",
        "Leaky ReLU: This activation function is a modification of the ReLU activation that allows a small, non-zero gradient for negative inputs.\n",
        "\n",
        "ELU (Exponential Linear Unit): This activation function is similar to the ReLU function but has a negative slope for negative inputs, ensuring that the activation function never saturates."
      ],
      "metadata": {
        "id": "M8T1tW0Z5qTI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. What is artificial neural network (ANN)? Explain some of the salient highlights in the\n",
        "different architectural options for ANN.**"
      ],
      "metadata": {
        "id": "xMCCOkFT6ZZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An Artificial Neural Network (ANN) is a machine learning model inspired by the structure and function of the human brain. It is a type of deep learning model that is composed of interconnected processing nodes, known as artificial neurons.\n",
        "\n",
        "There are several architectural options for ANNs, each with its own unique strengths and weaknesses:\n",
        "\n",
        "Feedforward Neural Networks: This is the simplest type of ANN, where information flows in only one direction, from input to output, through a series of connected nodes. There is no feedback loop in this architecture.\n",
        "\n",
        "Convolutional Neural Networks (ConvNets or CNNs): This architecture is used primarily in computer vision tasks, such as image classification and object detection. It is designed to automatically and adaptively learn spatial hierarchies of features through multiple layers of convolution and pooling operations.\n",
        "\n",
        "Recurrent Neural Networks (RNNs): This architecture is designed to process sequential data, such as time series or natural language processing. RNNs have a feedback loop that allows information to persist and be passed from one step of the sequence to the next.\n",
        "\n",
        "Autoencoders: This architecture is an unsupervised deep learning technique that learns to compress and reconstruct data in a lower-dimensional representation. Autoencoders can be used for dimensionality reduction, denoising, and generative models.\n",
        "\n",
        "Generative Adversarial Networks (GANs): This architecture consists of two neural networks, a generator and a discriminator, that compete against each other. The generator learns to produce new, synthetic samples that are similar to the training data, while the discriminator learns to distinguish between real and fake samples.\n",
        "\n",
        "Each type of architecture has its own specific use cases and is optimized for solving specific types of problems."
      ],
      "metadata": {
        "id": "SCxqT9HL6vi_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Explain the learning process of an ANN. Explain, with example, the challenge in assigning\n",
        "synaptic weights for the interconnection between neurons? How can this challenge be\n",
        "addressed?**"
      ],
      "metadata": {
        "id": "h-W1c8US66s_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The learning process of an Artificial Neural Network (ANN) involves updating the weights of the connections between neurons in order to minimize a loss function that measures the difference between the network's predicted output and the actual output. This is done through an optimization algorithm, such as gradient descent, which updates the weights in the direction that reduces the loss.\n",
        "\n",
        "The challenge in assigning synaptic weights for the interconnection between neurons lies in finding the optimal values for these weights that minimize the loss function. This can be difficult because the loss function is non-linear and can have many local minima, which can trap the optimization algorithm in a suboptimal solution.\n",
        "\n",
        "One way to address this challenge is by using a different optimization algorithm, such as conjugate gradient descent or BFGS, which are more efficient and effective at escaping local minima. Another way to address this challenge is by initializing the weights with small random values and using regularization techniques, such as L1 or L2 regularization, to prevent overfitting and encourage the network to find a more general solution.\n",
        "\n",
        "Finally, using an appropriate loss function that is well-suited to the task at hand, as well as using enough training data, can also help to ensure that the network converges to a good solution."
      ],
      "metadata": {
        "id": "Vidt_STB7ChH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Write short notes on:***\n",
        "1. Artificial neuron\n",
        "2. Multi-layer perceptron\n",
        "3. Deep learning\n",
        "4. Learning rate"
      ],
      "metadata": {
        "id": "V7qmDs2P7cPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-layer Perceptron (MLP): A Multi-layer Perceptron is a type of feedforward artificial neural network that consists of multiple layers of interconnected nodes, or artificial neurons. Each layer receives input from the previous layer, performs a calculation based on its weights, and passes the result to the next layer. MLPs are used for a wide variety of tasks, including classification, regression, and dimensionality reduction.\n",
        "\n",
        "Learning Rate: The learning rate is a hyperparameter in machine learning that determines the step size at which the optimizer updates the weights during training. The learning rate determines how quickly or slowly the model learns from the training data. If the learning rate is too high, the model may overshoot the optimal weights and oscillate or diverge, whereas if the learning rate is too low, the model may converge too slowly. The learning rate is an important factor that affects the performance of a machine learning model, and must be set carefully."
      ],
      "metadata": {
        "id": "MgO39uK77kC4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Write the difference between:-**\n",
        "\n",
        "1. Activation function vs threshold function\n",
        "2. Step function vs sigmoid function\n",
        "3. Single layer vs multi-layer perceptron"
      ],
      "metadata": {
        "id": "57vQcB0K7sQj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation Function vs Threshold Function:\n",
        "Activation functions are mathematical functions used in artificial neural networks to determine the output of a node, or artificial neuron, based on its input. They introduce non-linearity into the network and allow it to learn complex relationships between inputs and outputs.\n",
        "\n",
        "Threshold functions, on the other hand, are simple threshold-based activation functions that output either a 0 or 1 based on whether the input is above or below a certain threshold value. Threshold functions are used in binary classification problems and are less commonly used in modern neural networks due to their limited expressiveness compared to other activation functions.\n",
        "\n",
        "Step Function vs Sigmoid Function:\n",
        "The step function is a threshold-based activation function that outputs either a 0 or 1 based on whether the input is above or below a certain threshold value. The step function is commonly used in binary classification problems and is less commonly used in modern neural networks due to its binary output and lack of gradient, which makes it difficult to train.\n",
        "\n",
        "The sigmoid function is a smooth, S-shaped activation function that outputs values between 0 and 1. The sigmoid function is commonly used in logistic regression and is often used as an activation function in artificial neural networks due to its smooth and differentiable nature, which allows for gradient-based optimization algorithms to be used for training.\n",
        "\n",
        "Single Layer Perceptron vs Multi-layer Perceptron:\n",
        "A single layer perceptron is a type of artificial neural network with only one layer of nodes, or artificial neurons. It is a simple model that can be used for binary classification problems, but is limited in its ability to represent complex relationships between inputs and outputs.\n",
        "\n",
        "A multi-layer perceptron, on the other hand, is a type of artificial neural network with multiple layers of nodes, or artificial neurons. The multiple layers allow the network to learn complex relationships between inputs and outputs and to perform more advanced tasks, such as multi-class classification and regression. Multi-layer perceptrons are more powerful than single layer perceptrons and are widely used in a variety of applications."
      ],
      "metadata": {
        "id": "FgyOdfNG8gvA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZHEFySt5DbP"
      },
      "outputs": [],
      "source": []
    }
  ]
}