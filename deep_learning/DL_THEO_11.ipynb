{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**3. Write the Python code for a dense layer in terms of matrix multiplication.**"
      ],
      "metadata": {
        "id": "TF4goKvAeZZw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AQonsbjId9R0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def dense_layer(inputs, weights, biases):\n",
        "    # Matrix multiplication of inputs and weights\n",
        "    z = np.dot(inputs, weights)\n",
        "\n",
        "    # Add biases to the result of matrix multiplication\n",
        "    z = z + biases\n",
        "\n",
        "    # Return the result\n",
        "    return z\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The inputs is a 2-dimensional array with shape (batch_size, input_units), weights is a 2-dimensional array with shape (input_units, output_units), and biases is a 1-dimensional array with shape (output_units,). The resulting matrix has shape (batch_size, output_units)."
      ],
      "metadata": {
        "id": "-A82SAioex6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Write the Python code for a dense layer in plain Python (that is, with list comprehensions\n",
        "and functionality built into Python).**"
      ],
      "metadata": {
        "id": "cefKiLwKe4uY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_layer(inputs, weights, biases):\n",
        "    # Calculate the dot product of inputs and weights\n",
        "    z = [sum(i * w for i, w in zip(inputs_i, weights_j)) for inputs_i in inputs for weights_j in zip(*weights)]\n",
        "\n",
        "    # Reshape the result of the dot product into a 2D array\n",
        "    z = [z[i:i+len(biases)] for i in range(0, len(z), len(biases))]\n",
        "\n",
        "    # Add biases to each row of the result of the dot product\n",
        "    z = [[z_ij + b_j for z_ij, b_j in zip(z_i, biases)] for z_i in z]\n",
        "\n",
        "    # Return the result\n",
        "    return z\n"
      ],
      "metadata": {
        "id": "oUHIbYwtetzV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The inputs is a 2-dimensional list with shape (batch_size, input_units), weights is a 2-dimensional list with shape (input_units, output_units), and biases is a 1-dimensional list with shape (output_units,). The resulting list has shape (batch_size, output_units)."
      ],
      "metadata": {
        "id": "QWDVr8fffHbD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What is the “hidden size” of a layer?**\n"
      ],
      "metadata": {
        "id": "7u8RjqnXgIsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"hidden size\" of a layer refers to the number of neurons or units in the layer. It is called the \"hidden\" size because it is typically the number of neurons in the hidden layers of a neural network, as opposed to the input or output layer, which are also referred to as the \"visible\" layers."
      ],
      "metadata": {
        "id": "EbPgTuXZgX3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What does the t method do in PyTorch?**\n"
      ],
      "metadata": {
        "id": "sFK6CRsDgNN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In PyTorch, the t method transposes a tensor, which means it swaps the rows and columns of a matrix. It is equivalent to the transpose function in NumPy."
      ],
      "metadata": {
        "id": "Xq6KCd9BgcR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Why is matrix multiplication written in plain Python very slow?**"
      ],
      "metadata": {
        "id": "fT9UFkcLgSs2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix multiplication written in plain Python is slow due to the use of loops and list comprehensions, which can be computationally expensive. The code written in Python needs to iterate over each element in the input matrices, which leads to a large number of operations and slower performance. In contrast, NumPy and PyTorch use optimized algorithms and pre-compiled C/C++ code to perform matrix multiplication, which is much faster than code written in plain Python.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rHWcSh1Vggo7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. In matmul, why is ac==br?**\n"
      ],
      "metadata": {
        "id": "vz_IUh46g2Me"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In matrix multiplication (matmul), the condition ac == br is used to verify that the number of columns in the first matrix (a) is equal to the number of rows in the second matrix (b). This is a requirement for matrix multiplication, as the dot product of two matrices can only be calculated if the number of columns in the first matrix is equal to the number of rows in the second matrix."
      ],
      "metadata": {
        "id": "uTzOjDobhNWC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. In Jupyter Notebook, how do you measure the time taken for a single cell to execute?**\n"
      ],
      "metadata": {
        "id": "o4I_P-BKg-ek"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Jupyter Notebook, you can measure the time taken for a single cell to execute using the %timeit magic command. For example, if you want to measure the time taken to execute a single cell containing the following code:"
      ],
      "metadata": {
        "id": "pMVihHfQhR-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = [i for i in range(10000)]\n",
        "y = [i**2 for i in x]\n"
      ],
      "metadata": {
        "id": "a6fIUJ17heLQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the following code in the same cell:"
      ],
      "metadata": {
        "id": "L2eiNWgdhkN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit x = [i for i in range(10000)]\n",
        "y = [i**2 for i in x]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skxqbji4hoS9",
        "outputId": "d02e1a19-3cb8-49f9-f549-cda911c5c0d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "343 µs ± 6.98 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. What is elementwise arithmetic?9. In Jupyter Notebook, how do you measure the time taken for a single cell to execute?**"
      ],
      "metadata": {
        "id": "RzJVVVDjhIIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elementwise arithmetic refers to operations that are performed element-by-element on two or more arrays. For example, elementwise addition, subtraction, multiplication, or division, where each element in one array is combined with the corresponding element in another array to produce a new array. In NumPy and PyTorch, elementwise arithmetic operations are usually performed using broadcasting, which allows arrays with different shapes to be used in elementwise arithmetic operations."
      ],
      "metadata": {
        "id": "CwtsNl3Ch-dP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Write the PyTorch code to test whether every element of a is greater than the\n",
        "corresponding element of b.**"
      ],
      "metadata": {
        "id": "EwO6l_95iJY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor([1, 2, 3, 4, 5])\n",
        "b = torch.tensor([0, 1, 2, 3, 4])\n",
        "result = (a > b).all()\n",
        "\n",
        "if result:\n",
        "    print(\"Every element of a is greater than the corresponding element of b.\")\n",
        "else:\n",
        "    print(\"Not every element of a is greater than the corresponding element of b.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLnFayeVfEGb",
        "outputId": "bec0be8b-9b76-4662-9561-34ddc27a86e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every element of a is greater than the corresponding element of b.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The comparison operator > is used to compare the elements of a and b, and the all method is used to check if all elements in the resulting tensor are True. If every element of a is greater than the corresponding element of b, the result will be True and the message \"Every element of a is greater than the corresponding element of b\" will be printed."
      ],
      "metadata": {
        "id": "0M3WqkJyiZy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. What is a rank-0 tensor? How do you convert it to a plain Python data type?**\n"
      ],
      "metadata": {
        "id": "LH09PCjTjEIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A rank-0 tensor is a tensor with no dimensions or a scalar value. In PyTorch, a rank-0 tensor is represented by a tensor with shape (). To convert a rank-0 tensor to a plain Python data type, you can use the item method. For example:"
      ],
      "metadata": {
        "id": "jyLw9KzNjPP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor(3)\n",
        "b = a.item()\n",
        "print(b) # Output: 3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah0h9usOjR4z",
        "outputId": "bfd48e12-7451-411e-af4e-29978cdb92e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example above, a is a rank-0 tensor with value 3, and b is the equivalent plain Python data type."
      ],
      "metadata": {
        "id": "_vh2Z_CmjbIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. How does elementwise arithmetic help us speed up matmul?**"
      ],
      "metadata": {
        "id": "PbRfiJlzjIK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elementwise arithmetic does not directly help speed up matrix multiplication (matmul). Matrix multiplication is an inherently complex operation that involves multiple matrix-matrix or matrix-vector dot products, and cannot be significantly sped up by simple elementwise operations. However, elementwise arithmetic can be used to perform certain operations on arrays more efficiently, such as elementwise multiplication or division, which can be used to implement certain types of layers in neural networks. Additionally, the ability to perform elementwise operations on arrays allows for easier implementation and understanding of certain algorithms, such as activation functions, which can be applied elementwise to a tensor."
      ],
      "metadata": {
        "id": "CYTqutbBjf-r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Un40unIXiRmM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}